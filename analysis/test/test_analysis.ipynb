{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Bioinformatics-Research-Network/Scientific-Image-Search/blob/main/analysis/test/test_analysis.ipynb)\n",
    "\n",
    "\n",
    "This analysis is proof that the dev env is working as expected. It should be compiled by the CI workflow with the proper packages and then perform a basic analysis of MNIST.\n",
    "\n",
    "The `torch_env.yml` file defines the dependencies. The code block below will install it into the current environment. This is intended to cover the usecase in which only the current environment is exposed to the jupyter notebook. For local development, consider simply creating and activating a separate `torch_env` environment like so:\n",
    "\n",
    "```shell\n",
    "conda env create -n torch_env -f ../torch_env.yml\n",
    "conda activate torch_env\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate torch_env\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Skip this cell if running on colab...\n",
    "! conda env update --file ../torch_env.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mnist data from sklearn load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model on the data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=0)\n",
    "logreg = LogisticRegression(max_iter=5000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy:\", logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the pytorch nn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry the analysis using a deep neural network from pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Create a dataset class that inherits from torch.utils.data.Dataset\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create a model class that inherits from torch.nn.Module\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.linear(x), dim=1)\n",
    "    def predict(self, x):\n",
    "        return self.forward(x).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset object\n",
    "dataset = MNISTDataset(X_train, y_train)\n",
    "\n",
    "# Create a dataloader object\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Create a model object\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Create an optimizer object\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create a loss function object\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Iteration: 0 Loss: 6.30604887008667\n",
      "Epoch: 1 Iteration: 0 Loss: 0.508837103843689\n",
      "Epoch: 2 Iteration: 0 Loss: 0.45972394943237305\n",
      "Epoch: 3 Iteration: 0 Loss: 0.24492105841636658\n",
      "Epoch: 4 Iteration: 0 Loss: 0.18297936022281647\n",
      "Epoch: 5 Iteration: 0 Loss: 0.20093871653079987\n",
      "Epoch: 6 Iteration: 0 Loss: 0.21299907565116882\n",
      "Epoch: 7 Iteration: 0 Loss: 0.11195831745862961\n",
      "Epoch: 8 Iteration: 0 Loss: 0.08718807995319366\n",
      "Epoch: 9 Iteration: 0 Loss: 0.10586725920438766\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    for i, (data, target) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.float())\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch:\", epoch, \"Iteration:\", i, \"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9416666666666667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "# There is no .predict() method in the model class, so we need to define it\n",
    "model.predict = lambda x: model(x.float()).argmax(dim=1)\n",
    "# Need a tensor for the test data\n",
    "test_data = torch.tensor(X_test)\n",
    "# Predict the labels\n",
    "y_pred = model.predict(test_data)\n",
    "# Calculate the accuracy given that y_pred is a tensor and y_test is a list\n",
    "print(\"Accuracy:\", (y_pred.tolist() == y_test).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9a62650773836e8f10062b753e32c8319c1d1b289194fe99021056a7a33c9f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
